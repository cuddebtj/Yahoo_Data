{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from yfpy import YahooFantasySportsQuery\n",
    "from yfpy.utils import complex_json_handler, unpack_data\n",
    "from yfpy import get_logger\n",
    "from dotenv import load_dotenv\n",
    "from gspread_pandas import Spread\n",
    "\n",
    "from utils import (\n",
    "    get_season,\n",
    "    league_season_info,\n",
    "    google_sheet_upload,\n",
    "    sql_upload_table,\n",
    "    sql_grab_table,\n",
    ")\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "pd.set_option(\"display.max_colwidth\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "LOGGET = get_logger(__name__)\n",
    "LOG_OUTPUT = False\n",
    "logging.getLogger(\"yfpy.query\").setLevel(level=logging.INFO)\n",
    "\n",
    "PATH = Path.cwd().parents[0]\n",
    "# DATA_DIR = PATH / \"data\"\n",
    "\n",
    "# SEASON = get_season()\n",
    "# NFL_DATES_DF, LEAGUE_ID_DF = league_season_info()\n",
    "\n",
    "# TODAY = np.datetime64(\"today\", \"D\")\n",
    "# TODAY = np.datetime64(\"2021-09-28\")\n",
    "# NFL_WEEK = NFL_DATES_DF[\"Week\"][(NFL_DATES_DF[\"End_Date\"] >= TODAY) & (NFL_DATES_DF[\"Start_Date\"] <= TODAY)].values[0]\n",
    "# LEAGUE_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"league_ID\"].values[0]\n",
    "LEAGUE_ID = \"777818\"\n",
    "# GAME_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"game_ID\"].values[0]\n",
    "GAME_ID = \"273\"\n",
    "# WEEKS = list(range(NFL_WEEK, 0, -1))\n",
    "\n",
    "CONSUMER_KEY = os.getenv(\"yahoo_client_id\")\n",
    "CONSUMER_SECRET = os.getenv(\"yahoo_client_secret\")\n",
    "\n",
    "try:\n",
    "    yahoo_query = YahooFantasySportsQuery(\n",
    "        auth_dir=PATH,\n",
    "        league_id=LEAGUE_ID,\n",
    "        game_id=GAME_ID,\n",
    "        game_code=\"nfl\",\n",
    "        offline=False,\n",
    "        all_output_as_json=False,\n",
    "        consumer_key=CONSUMER_KEY,\n",
    "        consumer_secret=CONSUMER_SECRET,\n",
    "        browser_callback=True,\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 22:33:03.521 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 23:33:05.530 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 00:33:10.551 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 01:33:12.782 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 02:33:13.887 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/league/273.l.777818/players;player_keys=273.p.8101/stats;type=week;week=12?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/league/273.l.777818/players;player_keys=273.p.8101/stats;type=week;week=12?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 03:33:15.175 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 04:33:21.637 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 05:33:26.988 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 06:33:28.354 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 07:33:31.854 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 08:33:37.947 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 09:33:39.027 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 10:33:42.434 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 11:33:43.187 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 12:33:43.878 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 13:33:47.247 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:33:49.010 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 15:33:54.693 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 16:34:00.222 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 17:34:00.913 - ERROR - query.py - yfpy.query:197 - Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to retrieve data at URL https://fantasysports.yahooapis.com/fantasy/v2/game/273/metadata?format=json failed with error: \"Please provide valid credentials. OAuth oauth_problem=\"token_expired\", realm=\"yahooapis.com\"\"\n"
     ]
    }
   ],
   "source": [
    "# players = sql_grab_table(\"Players\")\n",
    "players = pd.read_csv('players.csv')\n",
    "player_keys = list(players[\"player_key\"])\n",
    "player_stats = pd.DataFrame()\n",
    "for k in player_keys:\n",
    "    for w in range(1, 18):\n",
    "        try:\n",
    "            r1 = yahoo_query.get_player_stats_by_week(k, w)\n",
    "            r2 = yahoo_query.get_player_percent_owned_by_week(k, w)\n",
    "\n",
    "        except Exception as e:\n",
    "            if 'token_expired' in str(e):\n",
    "                print(e)\n",
    "                yahoo_query._authenticate()\n",
    "            else:\n",
    "                print(f'Error with player stats at player_key {k} and week {w}.\\n{e}\\nRetrying in 15 minutes.')\n",
    "                time.sleep(1800)\n",
    "                yahoo_query._authenticate()\n",
    "\n",
    "            r1 = yahoo_query.get_player_stats_by_week(k, w)\n",
    "            r2 = yahoo_query.get_player_percent_owned_by_week(k, w)\n",
    "\n",
    "        time.sleep(5)\n",
    "        data = complex_json_handler(r1)\n",
    "        player = pd.json_normalize(data)\n",
    "        stats = data[\"player_stats\"][\"stats\"]\n",
    "        player_stat_week = pd.DataFrame()\n",
    "\n",
    "        for r in stats:\n",
    "            stat = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "            stat[\"player_key\"] = player[\"player_key\"]\n",
    "            stat[\"week\"] = player[\"player_stats.week\"]\n",
    "            stat[\"total_points_week\"] = player[\"player_points.total\"]\n",
    "            player_stat_week = pd.concat([player_stat_week, stat])\n",
    "\n",
    "        ownership = pd.json_normalize(complex_json_handler(r2))\n",
    "        if 'percent_owned.value' not in ownership.columns:\n",
    "            ownership['percent_owned.value'] = 0\n",
    "\n",
    "        ownership = ownership[[\"player_key\", \"percent_owned.value\", \"percent_owned.delta\"]]\n",
    "\n",
    "        player_stat_week = player_stat_week.merge(\n",
    "            ownership,\n",
    "            how=\"outer\",\n",
    "            left_on=\"player_key\",\n",
    "            right_on=\"player_key\",\n",
    "        )\n",
    "\n",
    "        player_stats = pd.concat([player_stats, player_stat_week])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class league_season_data(object):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        auth_dir: Path,\n",
    "        league_id: str,\n",
    "        game_id: int = None,\n",
    "        game_code: str = \"nfl\",\n",
    "        offline: bool = False,\n",
    "        all_output_as_json: bool = False,\n",
    "        consumer_key: str = None,\n",
    "        consumer_secret: str = None,\n",
    "        browser_callback: bool = True,\n",
    "    ):\n",
    "\n",
    "        self._auth_dir = auth_dir\n",
    "        self._consumer_key = consumer_key\n",
    "        self._consumer_secret = consumer_secret\n",
    "        self._browser_callback = browser_callback\n",
    "\n",
    "        self.league_id = league_id\n",
    "        self.game_id = game_id\n",
    "        self.game_code = game_code\n",
    "\n",
    "        self.offline = offline\n",
    "        self.all_output_as_json = all_output_as_json\n",
    "\n",
    "    def _yahoo_query(self):\n",
    "\n",
    "        try:\n",
    "            yahoo_query = YahooFantasySportsQuery(\n",
    "                auth_dir=self._auth_dir,\n",
    "                league_id=self.league_id,\n",
    "                game_id=self.game_id,\n",
    "                game_code=self.game_code,\n",
    "                offline=self.offline,\n",
    "                all_output_as_json=self.all_output_as_json,\n",
    "                consumer_key=self._consumer_key,\n",
    "                consumer_secret=self._consumer_secret,\n",
    "                browser_callback=self._browser_callback,\n",
    "            )\n",
    "\n",
    "            return yahoo_query\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def metadata(self, first_time=\"no\"):\n",
    "        response = complex_json_handler(yahoo_query.get_league_metadata())\n",
    "        league_metadata = pd.json_normalize(response)\n",
    "\n",
    "        league_metadata[\"game_id\"] = self.game_id\n",
    "        league_metadata.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_metadata,\n",
    "                table_name=\"LeagueMetaData\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_metadata,\n",
    "                table_name=\"LeagueMetaData\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return league_metadata\n",
    "\n",
    "\n",
    "    def set_roster_pos_stat_cat(self, first_time=\"no\"):\n",
    "        response = complex_json_handler(yahoo_query.get_league_settings())\n",
    "\n",
    "        league_settings = pd.json_normalize(response)\n",
    "        league_settings.drop(\n",
    "            [\"roster_positions\", \"stat_categories.stats\", \"stat_modifiers.stats\"],\n",
    "            axis=1,\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        league_settings[\"game_id\"] = self.game_id\n",
    "        league_settings[\"league_id\"] = self.league_id\n",
    "        league_settings.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        roster_positions = pd.DataFrame()\n",
    "        for r in response[\"roster_positions\"]:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"roster_position\"]))\n",
    "            roster_positions = pd.concat([roster_positions, row])\n",
    "\n",
    "        roster_positions[\"game_id\"] = self.game_id\n",
    "        roster_positions[\"league_id\"] = self.league_id\n",
    "        roster_positions.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        stat_categories = pd.DataFrame()\n",
    "        for r in response[\"stat_categories\"][\"stats\"]:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "            try:\n",
    "                row[\"position_type\"] = complex_json_handler(\n",
    "                    complex_json_handler(r[\"stat\"])[\"stat_position_types\"][\n",
    "                        \"stat_position_type\"\n",
    "                    ]\n",
    "                )[\"position_type\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                row[\"is_only_display_stat\"] = complex_json_handler(\n",
    "                    complex_json_handler(r[\"stat\"])[\"stat_position_types\"][\n",
    "                        \"stat_position_type\"\n",
    "                    ]\n",
    "                )[\"is_only_display_stat\"]\n",
    "            except:\n",
    "                row[\"is_only_display_stat\"] = 0\n",
    "\n",
    "            try:\n",
    "                row.drop(\"stat_position_types.stat_position_type\", axis=1, inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            stat_categories = pd.concat([stat_categories, row])\n",
    "\n",
    "        stat_categories[\"game_id\"] = self.game_id\n",
    "        stat_categories[\"league_id\"] = self.league_id\n",
    "\n",
    "        stat_modifiers = pd.DataFrame()\n",
    "        for r in response[\"stat_modifiers\"][\"stats\"]:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "            stat_modifiers = pd.concat([stat_modifiers, row])\n",
    "\n",
    "        stat_modifiers.rename(columns={\"value\": \"stat_modifier\"}, inplace=True)\n",
    "\n",
    "        stat_categories = stat_categories.merge(\n",
    "            stat_modifiers, how=\"outer\", on=\"stat_id\"\n",
    "        )\n",
    "        stat_categories.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_settings,\n",
    "                table_name=\"LeagueSettings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=roster_positions,\n",
    "                table_name=\"RosterPositions\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=stat_categories,\n",
    "                table_name=\"StatCategories\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_settings,\n",
    "                table_name=\"LeagueSettings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=roster_positions,\n",
    "                table_name=\"RosterPositions\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=stat_categories,\n",
    "                table_name=\"StatCategories\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return league_settings, roster_positions, stat_categories\n",
    "\n",
    "\n",
    "    def teams_list(self, first_time=\"no\"):\n",
    "        response = yahoo_query.get_league_teams()\n",
    "        teams = pd.DataFrame()\n",
    "        for r in response:\n",
    "            team = pd.json_normalize(complex_json_handler(r[\"team\"]))\n",
    "            try:\n",
    "                manager = pd.json_normalize(\n",
    "                    complex_json_handler(team[\"managers.manager\"][0])\n",
    "                )\n",
    "            except:\n",
    "                manager = pd.json_normalize(\n",
    "                    complex_json_handler(team[\"managers\"][0][0][\"manager\"])\n",
    "                )\n",
    "            team = pd.concat([team, manager], axis=1)\n",
    "            if \"clinched_playoffs\" not in team.columns:\n",
    "                team[\"clinched_playoffs\"] = 0\n",
    "            team = team[\n",
    "                [\n",
    "                    \"clinched_playoffs\",\n",
    "                    \"has_draft_grade\",\n",
    "                    \"league_scoring_type\",\n",
    "                    \"name\",\n",
    "                    \"number_of_moves\",\n",
    "                    \"number_of_trades\",\n",
    "                    \"team_id\",\n",
    "                    \"team_key\",\n",
    "                    \"waiver_priority\",\n",
    "                    \"roster_adds.coverage_type\",\n",
    "                    \"roster_adds.coverage_value\",\n",
    "                    \"roster_adds.value\",\n",
    "                    \"guid\",\n",
    "                    \"manager_id\",\n",
    "                    \"nickname\",\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "            teams = pd.concat([teams, team], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "        teams[\"name\"] = teams[\"name\"].str.decode(\"utf-8\")\n",
    "\n",
    "        teams[\"game_id\"] = self.game_id\n",
    "        teams[\"league_id\"] = self.league_id\n",
    "        teams.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=teams,\n",
    "                table_name=\"Teams\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=teams,\n",
    "                table_name=\"Teams\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return teams\n",
    "\n",
    "\n",
    "    def players_list(self, first_time=\"no\"):\n",
    "        response = yahoo_query.get_league_players()\n",
    "        players = pd.DataFrame()\n",
    "        for r in response:\n",
    "            player = pd.json_normalize(complex_json_handler(r[\"player\"]))\n",
    "            try:\n",
    "                draft_analysis = pd.json_normalize(complex_json_handler(yahoo_query.get_player_draft_analysis(player[\"player_key\"][0])))\n",
    "\n",
    "            except Exception as e:\n",
    "                if 'token_expired' in str(e):\n",
    "                    yahoo_query._authenticate()\n",
    "                else:\n",
    "                    print('Retrying after sleeping 15 min.')\n",
    "                    time.sleep(900)\n",
    "                    yahoo_query._authenticate()\n",
    "\n",
    "                draft_analysis = pd.json_normalize(complex_json_handler(yahoo_query.get_player_draft_analysis(player[\"player_key\"][0])))\n",
    "\n",
    "            draft_analysis = draft_analysis[\n",
    "                [\n",
    "                    \"draft_analysis.average_pick\",\n",
    "                    \"draft_analysis.average_round\",\n",
    "                    \"draft_analysis.average_cost\",\n",
    "                    \"draft_analysis.percent_drafted\",\n",
    "                ]\n",
    "            ]\n",
    "            player = pd.concat([player, draft_analysis], axis=1)\n",
    "            if \"status\" not in player.columns:\n",
    "                player[\"status\"] = np.nan\n",
    "\n",
    "            players = pd.concat([players, player], ignore_index=True)\n",
    "            time.sleep(2.5)\n",
    "\n",
    "\n",
    "        players[\"game_id\"] = self.game_id\n",
    "        players[\"league_id\"] = self.league_id\n",
    "        players.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=players,\n",
    "                table_name=\"Players\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=players,\n",
    "                table_name=\"Players\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return players\n",
    "\n",
    "\n",
    "    def draft_results(self, first_time=\"no\"):\n",
    "        response = yahoo_query.get_league_draft_results()\n",
    "        draft_results = pd.DataFrame()\n",
    "        for r in response:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"draft_result\"]))\n",
    "            draft_results = pd.concat([draft_results, row])\n",
    "\n",
    "        draft_results[\"game_id\"] = self.game_id\n",
    "        draft_results[\"league_id\"] = self.league_id\n",
    "        draft_results.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=draft_results,\n",
    "                table_name=\"DraftResults\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=draft_results,\n",
    "                table_name=\"DraftResults\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return draft_results\n",
    "\n",
    "\n",
    "    def matchups_by_week(self, first_time=\"no\"):\n",
    "        m = []\n",
    "        team_a = pd.DataFrame()\n",
    "        team_b = pd.DataFrame()\n",
    "        response = yahoo_query.get_league_matchups_by_week(1)\n",
    "        for data in response:\n",
    "            m.append(complex_json_handler(data[\"matchup\"]))\n",
    "        matchups = pd.DataFrame()\n",
    "        for r in m:\n",
    "            matchup = pd.json_normalize(r)\n",
    "            matchup = matchup[\n",
    "                [\n",
    "                    \"is_consolation\",\n",
    "                    \"is_matchup_recap_available\",\n",
    "                    \"is_playoffs\",\n",
    "                    \"is_tied\",\n",
    "                    \"matchup_recap_title\",\n",
    "                    \"matchup_recap_url\",\n",
    "                    \"status\",\n",
    "                    \"week\",\n",
    "                    \"week_end\",\n",
    "                    \"week_start\",\n",
    "                    \"winner_team_key\",\n",
    "                ]\n",
    "            ]\n",
    "            try:\n",
    "                team_a = pd.json_normalize(\n",
    "                    complex_json_handler(r[\"matchup_grades\"][0][\"matchup_grade\"])\n",
    "                )\n",
    "                team_a[\"points\"] = complex_json_handler(r[\"teams\"][0][\"team\"])[\n",
    "                    \"team_points\"\n",
    "                ][\"total\"]\n",
    "                team_a[\"projected_points\"] = complex_json_handler(\n",
    "                    r[\"teams\"][0][\"team\"]\n",
    "                )[\"team_projected_points\"][\"total\"]\n",
    "\n",
    "            except:\n",
    "                team_a = pd.json_normalize(complex_json_handler(r[\"teams\"][0][\"team\"]))\n",
    "                team_a = team_a[\n",
    "                    [\"team_key\", \"team_points.total\", \"team_projected_points.total\"]\n",
    "                ]\n",
    "                team_a[\"grade\"] = np.nan\n",
    "\n",
    "            team_a = team_a.add_prefix(\"team_a_\")\n",
    "\n",
    "            try:\n",
    "                team_b = pd.json_normalize(\n",
    "                    complex_json_handler(r[\"matchup_grades\"][1][\"matchup_grade\"])\n",
    "                )\n",
    "                team_b[\"points\"] = complex_json_handler(r[\"teams\"][1][\"team\"])[\n",
    "                    \"team_points\"\n",
    "                ][\"total\"]\n",
    "                team_b[\"projected_points\"] = complex_json_handler(\n",
    "                    r[\"teams\"][1][\"team\"]\n",
    "                )[\"team_projected_points\"][\"total\"]\n",
    "\n",
    "            except:\n",
    "                team_b = pd.json_normalize(complex_json_handler(r[\"teams\"][1][\"team\"]))\n",
    "                team_b = team_b[\n",
    "                    [\"team_key\", \"team_points.total\", \"team_projected_points.total\"]\n",
    "                ]\n",
    "                team_b[\"grade\"] = np.nan\n",
    "            team_b = team_b.add_prefix(\"team_b_\")\n",
    "\n",
    "            matchup = pd.concat([matchup, team_a, team_b], axis=1)\n",
    "\n",
    "            matchups = pd.concat([matchups, matchup])\n",
    "\n",
    "        try:\n",
    "            matchups.drop([\"teams\", \"matchup_grades\"], axis=1, inplace=True)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        matchups[\"game_id\"] = self.game_id\n",
    "        matchups[\"league_id\"] = self.league_id\n",
    "        matchups.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=matchups,\n",
    "                table_name=\"Matchups\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=matchups,\n",
    "                table_name=\"Matchups\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return matchups\n",
    "\n",
    "\n",
    "    def team_standings(self, first_time=\"no\"):\n",
    "        standings = pd.DataFrame()\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                response = yahoo_query.get_team_standings(i)\n",
    "                if bool(response) == True:\n",
    "                    row = pd.json_normalize(complex_json_handler(response))\n",
    "                    row[\"team_id\"] = i\n",
    "                    standings = pd.concat([standings, row])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        standings[\"game_id\"] = self.game_id\n",
    "        standings[\"league_id\"] = self.league_id\n",
    "        standings.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=standings,\n",
    "                table_name=\"Standings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=standings,\n",
    "                table_name=\"Standings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return standings\n",
    "\n",
    "\n",
    "    def team_roster_by_week(self, first_time=\"no\"):\n",
    "        team_rosters = pd.DataFrame()\n",
    "        for t in range(1, 13):\n",
    "            try:\n",
    "                for w in range(1, 19):\n",
    "                    try:\n",
    "                        response = complex_json_handler(yahoo_query.get_team_roster_by_week(t, w))\n",
    "                        row = pd.json_normalize(complex_json_handler(response[\"players\"][0][\"player\"]))\n",
    "                        row[\"team_id\"] = t\n",
    "                        row[\"week\"] = w\n",
    "                        team_rosters = pd.concat([team_rosters, row])\n",
    "                        time.sleep(1)\n",
    "                    except:\n",
    "                        print(f'team: {t}\\nweek: {w}')\n",
    "                        continue\n",
    "            except:\n",
    "                print(f'team: {t}\\nweek: {w}')\n",
    "                continue\n",
    "\n",
    "        team_rosters[\"game_id\"] = self.game_id\n",
    "        team_rosters[\"league_id\"] = self.league_id\n",
    "        team_rosters.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=team_rosters,\n",
    "                table_name=\"TeamRosters\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=team_rosters,\n",
    "                table_name=\"TeamRosters\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return team_rosters\n",
    "\n",
    "\n",
    "    def player_stats_by_week(self, first_time=\"no\"):\n",
    "        players = sql_grab_table(\"Players\")\n",
    "        player_keys = list(players[\"player_key\"])\n",
    "        player_stats = pd.DataFrame()\n",
    "        for k in player_keys:\n",
    "            for w in range(1, 18):\n",
    "                try:\n",
    "                    r1 = yahoo_query.get_player_stats_by_week(k, w)\n",
    "                    r2 = yahoo_query.get_player_percent_owned_by_week(k, w)\n",
    "\n",
    "                except Exception as e:\n",
    "                    if 'token_expired' in str(e):\n",
    "                        print(e)\n",
    "                        yahoo_query._authenticate()\n",
    "                    else:\n",
    "                        print(f'Error with player stats at player_key {k} and week {w}.\\n{e}\\nRetrying in 15 minutes.')\n",
    "                        time.sleep(1800)\n",
    "                        yahoo_query._authenticate()\n",
    "\n",
    "                    r1 = yahoo_query.get_player_stats_by_week(k, w)\n",
    "                    r2 = yahoo_query.get_player_percent_owned_by_week(k, w)\n",
    "\n",
    "                time.sleep(4.8)\n",
    "                data = complex_json_handler(r1)\n",
    "                player = pd.json_normalize(data)\n",
    "                stats = data[\"player_stats\"][\"stats\"]\n",
    "                player_stat_week = pd.DataFrame()\n",
    "\n",
    "                for r in stats:\n",
    "                    stat = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "                    stat[\"player_key\"] = player[\"player_key\"]\n",
    "                    stat[\"week\"] = player[\"player_stats.week\"]\n",
    "                    stat[\"total_points_week\"] = player[\"player_points.total\"]\n",
    "                    player_stat_week = pd.concat([player_stat_week, stat])\n",
    "\n",
    "                ownership = pd.json_normalize(complex_json_handler(r2))\n",
    "                if 'percent_owned.value' not in ownership.columns:\n",
    "                    ownership['percent_owned.value'] = 0\n",
    "\n",
    "                ownership = ownership[[\"player_key\", \"percent_owned.value\", \"percent_owned.delta\"]]\n",
    "\n",
    "                player_stat_week = player_stat_week.merge(\n",
    "                    ownership,\n",
    "                    how=\"outer\",\n",
    "                    left_on=\"player_key\",\n",
    "                    right_on=\"player_key\",\n",
    "                )\n",
    "\n",
    "        player_stats = pd.concat([player_stats, player_stat_week])\n",
    "\n",
    "        player_stats[\"game_id\"] = self.game_id\n",
    "        player_stats[\"league_id\"] = self.leauge_id\n",
    "        player_stats.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=player_stats,\n",
    "                table_name=\"PlayerStats\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=player_stats,\n",
    "                table_name=\"PlayerStats\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return player_stats\n",
    "\n",
    "\n",
    "    def all_game_keys(self):\n",
    "        response = unpack_data(yahoo_query.get_all_yahoo_fantasy_game_keys())\n",
    "        league_keys = pd.read_csv(\"../assests/ID.csv\")\n",
    "        game_keys = pd.DataFrame()\n",
    "        for r in response:\n",
    "            row = pd.DataFrame(complex_json_handler(r[\"game\"]), index=[0])\n",
    "            game_keys = pd.concat([game_keys, row])\n",
    "\n",
    "        game_keys.reset_index(drop=True, inplace=True)\n",
    "        game_keys = game_keys[game_keys[\"season\"] >= 2012]\n",
    "        game_keys = game_keys.merge(\n",
    "            league_keys,\n",
    "            how=\"outer\",\n",
    "            left_on=[\"game_id\", \"season\"],\n",
    "            right_on=[\"game_id\", \"season\"],\n",
    "        )\n",
    "        game_keys.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        sql_upload_table(\n",
    "            dataframe=game_keys,\n",
    "            table_name=\"GameKeys\",\n",
    "            data_schema=\"dbo\",\n",
    "            chunksize=500,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        return game_keys\n",
    "\n",
    "\n",
    "    def all_nfl_weeks(self):\n",
    "        game_keys = sql_grab_table(\"GameKeys\")\n",
    "        game_id = list(game_keys[\"game_id\"])\n",
    "        weeks = pd.DataFrame()\n",
    "        for g in game_id:\n",
    "            response = yahoo_query.get_game_weeks_by_game_id(g)\n",
    "            for r in response:\n",
    "                row = pd.json_normalize(complex_json_handler(r[\"game_week\"]))\n",
    "                row[\"game_id\"] = g\n",
    "                weeks = pd.concat([weeks, row])\n",
    "\n",
    "        weeks.rename(columns={\"display_name\": \"week\"}, inplace=True)\n",
    "        weeks.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        sql_upload_table(\n",
    "            dataframe=weeks,\n",
    "            table_name=\"NFLWeeks\",\n",
    "            data_schema=\"dbo\",\n",
    "            chunksize=500,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        return weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = get_season()\n",
    "NFL_DATES_DF, LEAGUE_ID_DF = league_season_info()\n",
    "# TODAY = np.datetime64(\"today\", \"D\")\n",
    "TODAY = np.datetime64(\"2021-09-28\")\n",
    "NFL_WEEK = NFL_DATES_DF[\"Week\"][(NFL_DATES_DF[\"End_Date\"] >= TODAY) & (NFL_DATES_DF[\"Start_Date\"] <= TODAY)].values[0]\n",
    "WEEKS = list(range(NFL_WEEK, 0, -1))\n",
    "\n",
    "\n",
    "\n",
    "PATH = Path.cwd().parents[0]\n",
    "LEAGUE_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"league_ID\"].values[0]\n",
    "GAME_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"game_ID\"].values[0]\n",
    "CONSUMER_KEY = os.getenv(\"yahoo_client_id\")\n",
    "CONSUMER_SECRET = os.getenv(\"yahoo_client_secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time = \"yes\"\n",
    "league = league_season_data(\n",
    "    auth_dir=PATH,\n",
    "    league_id=LEAGUE_ID,\n",
    "    game_id=GAME_ID,\n",
    "    game_code=\"nfl\",\n",
    "    offline=False,\n",
    "    all_output_as_json=False,\n",
    "    consumer_key=CONSUMER_KEY,\n",
    "    consumer_secret=CONSUMER_SECRET,\n",
    "    browser_callback=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29258400a8f826869c35241d002ab1a2d58355eacb0fc692319d3b839b315963"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('yahoo.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
