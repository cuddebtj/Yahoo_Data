{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from yfpy import YahooFantasySportsQuery\n",
    "from yfpy.utils import complex_json_handler, unpack_data\n",
    "from yfpy import get_logger\n",
    "from dotenv import load_dotenv\n",
    "from gspread_pandas import Spread\n",
    "\n",
    "from utils import (\n",
    "    get_season,\n",
    "    league_season_info,\n",
    "    google_sheet_upload,\n",
    "    sql_upload_table,\n",
    "    sql_grab_table,\n",
    ")\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "pd.set_option(\"display.max_colwidth\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "LOGGET = get_logger(__name__)\n",
    "LOG_OUTPUT = False\n",
    "logging.getLogger(\"yfpy.query\").setLevel(level=logging.INFO)\n",
    "\n",
    "PATH = Path.cwd().parents[0]\n",
    "# DATA_DIR = PATH / \"data\"\n",
    "\n",
    "# SEASON = get_season()\n",
    "# NFL_DATES_DF, LEAGUE_ID_DF = league_season_info()\n",
    "\n",
    "# TODAY = np.datetime64(\"today\", \"D\")\n",
    "# TODAY = np.datetime64(\"2021-09-28\")\n",
    "# NFL_WEEK = NFL_DATES_DF[\"Week\"][(NFL_DATES_DF[\"End_Date\"] >= TODAY) & (NFL_DATES_DF[\"Start_Date\"] <= TODAY)].values[0]\n",
    "# LEAGUE_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"league_ID\"].values[0]\n",
    "LEAGUE_ID = \"777818\"\n",
    "# GAME_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"game_ID\"].values[0]\n",
    "GAME_ID = \"273\"\n",
    "# WEEKS = list(range(NFL_WEEK, 0, -1))\n",
    "\n",
    "CONSUMER_KEY = os.getenv(\"yahoo_client_id\")\n",
    "CONSUMER_SECRET = os.getenv(\"yahoo_client_secret\")\n",
    "\n",
    "try:\n",
    "    yahoo_query = YahooFantasySportsQuery(\n",
    "        auth_dir=PATH,\n",
    "        league_id=LEAGUE_ID,\n",
    "        game_id=GAME_ID,\n",
    "        game_code=\"nfl\",\n",
    "        offline=False,\n",
    "        all_output_as_json=False,\n",
    "        consumer_key=CONSUMER_KEY,\n",
    "        consumer_secret=CONSUMER_SECRET,\n",
    "        browser_callback=True,\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['percent_owned.value'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cudde\\OneDrive\\Programing\\Python-Projects\\Yahoo_Data\\scripts\\main.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=32'>33</a>\u001b[0m     player_stat_week \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([player_stats_week, stat])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=34'>35</a>\u001b[0m ownership \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(complex_json_handler(r2))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=35'>36</a>\u001b[0m ownership \u001b[39m=\u001b[39m ownership[[\u001b[39m\"\u001b[39;49m\u001b[39mplayer_key\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpercent_owned.value\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpercent_owned.delta\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=37'>38</a>\u001b[0m player_stat_week \u001b[39m=\u001b[39m player_stat_week\u001b[39m.\u001b[39mmerge(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=38'>39</a>\u001b[0m     ownership,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=39'>40</a>\u001b[0m     how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=40'>41</a>\u001b[0m     left_on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplayer_key\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=41'>42</a>\u001b[0m     right_on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplayer_key\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=42'>43</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cudde/OneDrive/Programing/Python-Projects/Yahoo_Data/scripts/main.ipynb#ch0000005?line=44'>45</a>\u001b[0m player_stats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([player_stats, player_stat_week])\n",
      "File \u001b[1;32mc:\\Users\\cudde\\OneDrive\\Programing\\Python-Projects\\Yahoo_Data\\yahoo.venv\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\cudde\\OneDrive\\Programing\\Python-Projects\\Yahoo_Data\\yahoo.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cudde\\OneDrive\\Programing\\Python-Projects\\Yahoo_Data\\yahoo.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['percent_owned.value'] not in index\""
     ]
    }
   ],
   "source": [
    "# players = sql_grab_table(\"Players\")\n",
    "players = pd.read_csv('players.csv')\n",
    "player_keys = list(players[\"player_key\"])\n",
    "player_stats = pd.DataFrame()\n",
    "for k in player_keys:\n",
    "    for w in range(1, 18):\n",
    "        try:\n",
    "            r1 = yahoo_query.get_player_stats_by_week(k, w)\n",
    "            r2 = yahoo_query.get_player_percent_owned_by_week(k, w)\n",
    "\n",
    "        except Exception as e:\n",
    "            if 'token_expired' in str(e):\n",
    "                print(e)\n",
    "                yahoo_query._authenticate()\n",
    "            else:\n",
    "                print(f'Error with player stats at player_key {k} and week {w}.\\n{e}\\nRetrying in 15 minutes.')\n",
    "                time.sleep(900)\n",
    "                yahoo_query._authenticate()\n",
    "\n",
    "            r1 = yahoo_query.get_player_stats_by_week(k, w)\n",
    "            r2 = yahoo_query.get_player_percent_owned_by_week(k, w)\n",
    "\n",
    "        data = complex_json_handler(r1)\n",
    "        player = pd.json_normalize(data)\n",
    "        stats = data[\"player_stats\"][\"stats\"]\n",
    "        player_stats_week = pd.DataFrame()\n",
    "\n",
    "        for r in stats:\n",
    "            stat = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "            stat[\"player_key\"] = player[\"player_key\"]\n",
    "            stat[\"week\"] = player[\"player_stats.week\"]\n",
    "            stat[\"total_points_week\"] = player[\"player_points.total\"]\n",
    "            player_stat_week = pd.concat([player_stats_week, stat])\n",
    "\n",
    "        ownership = pd.json_normalize(complex_json_handler(r2))\n",
    "        ownership = ownership[[\"player_key\", \"percent_owned.value\", \"percent_owned.delta\"]]\n",
    "\n",
    "        player_stat_week = player_stat_week.merge(\n",
    "            ownership,\n",
    "            how=\"outer\",\n",
    "            left_on=\"player_key\",\n",
    "            right_on=\"player_key\",\n",
    "        )\n",
    "\n",
    "        player_stats = pd.concat([player_stats, player_stat_week])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_position</th>\n",
       "      <th>editorial_player_key</th>\n",
       "      <th>editorial_team_abbr</th>\n",
       "      <th>editorial_team_full_name</th>\n",
       "      <th>editorial_team_key</th>\n",
       "      <th>eligible_positions</th>\n",
       "      <th>is_undroppable</th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_key</th>\n",
       "      <th>position_type</th>\n",
       "      <th>primary_position</th>\n",
       "      <th>uniform_number</th>\n",
       "      <th>bye_weeks.week</th>\n",
       "      <th>headshot.size</th>\n",
       "      <th>headshot.url</th>\n",
       "      <th>name.ascii_first</th>\n",
       "      <th>name.ascii_last</th>\n",
       "      <th>name.first</th>\n",
       "      <th>name.full</th>\n",
       "      <th>name.last</th>\n",
       "      <th>percent_owned.coverage_type</th>\n",
       "      <th>percent_owned.week</th>\n",
       "      <th>percent_owned.delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K</td>\n",
       "      <td>nfl.p.3888</td>\n",
       "      <td>Chi</td>\n",
       "      <td>Chicago Bears</td>\n",
       "      <td>nfl.t.3</td>\n",
       "      <td>[K]</td>\n",
       "      <td>0</td>\n",
       "      <td>3888</td>\n",
       "      <td>273.p.3888</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>small</td>\n",
       "      <td>https://s.yimg.com/iu/api/res/1.2/TcM85WhJ.fAOHWf2QKLjIw--~C/YXBwaWQ9eXNwb3J0cztjaD0yMDA7Y3I9MTtjdz0xNTM7ZHg9NzQ7ZHk9MDtmaT11bGNyb3A7aD02MDtxPTEwMDt3PTQ2/https://s.yimg.com/dh/ap/default/140828/silhouette@2x.png</td>\n",
       "      <td>Olindo</td>\n",
       "      <td>Mare</td>\n",
       "      <td>Olindo</td>\n",
       "      <td>Olindo Mare</td>\n",
       "      <td>Mare</td>\n",
       "      <td>week</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  display_position editorial_player_key editorial_team_abbr  \\\n",
       "0                K           nfl.p.3888                 Chi   \n",
       "\n",
       "  editorial_team_full_name editorial_team_key eligible_positions  \\\n",
       "0            Chicago Bears            nfl.t.3                [K]   \n",
       "\n",
       "   is_undroppable  player_id  player_key position_type primary_position  \\\n",
       "0               0       3888  273.p.3888             K                K   \n",
       "\n",
       "   uniform_number  bye_weeks.week headshot.size  \\\n",
       "0              10               6         small   \n",
       "\n",
       "                                                                                                                                                                                                          headshot.url  \\\n",
       "0  https://s.yimg.com/iu/api/res/1.2/TcM85WhJ.fAOHWf2QKLjIw--~C/YXBwaWQ9eXNwb3J0cztjaD0yMDA7Y3I9MTtjdz0xNTM7ZHg9NzQ7ZHk9MDtmaT11bGNyb3A7aD02MDtxPTEwMDt3PTQ2/https://s.yimg.com/dh/ap/default/140828/silhouette@2x.png   \n",
       "\n",
       "  name.ascii_first name.ascii_last name.first    name.full name.last  \\\n",
       "0           Olindo            Mare     Olindo  Olindo Mare      Mare   \n",
       "\n",
       "  percent_owned.coverage_type  percent_owned.week  percent_owned.delta  \n",
       "0                        week                   6                 -1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class league_season_data(object):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        auth_dir: Path,\n",
    "        league_id: str,\n",
    "        game_id: int = None,\n",
    "        game_code: str = \"nfl\",\n",
    "        offline: bool = False,\n",
    "        all_output_as_json: bool = False,\n",
    "        consumer_key: str = None,\n",
    "        consumer_secret: str = None,\n",
    "        browser_callback: bool = True,\n",
    "    ):\n",
    "\n",
    "        self._auth_dir = auth_dir\n",
    "        self._consumer_key = consumer_key\n",
    "        self._consumer_secret = consumer_secret\n",
    "        self._browser_callback = browser_callback\n",
    "\n",
    "        self.league_id = league_id\n",
    "        self.game_id = game_id\n",
    "        self.game_code = game_code\n",
    "\n",
    "        self.offline = offline\n",
    "        self.all_output_as_json = all_output_as_json\n",
    "\n",
    "    def _yahoo_query(self):\n",
    "\n",
    "        try:\n",
    "            yahoo_query = YahooFantasySportsQuery(\n",
    "                auth_dir=self._auth_dir,\n",
    "                league_id=self.league_id,\n",
    "                game_id=self.game_id,\n",
    "                game_code=self.game_code,\n",
    "                offline=self.offline,\n",
    "                all_output_as_json=self.all_output_as_json,\n",
    "                consumer_key=self._consumer_key,\n",
    "                consumer_secret=self._consumer_secret,\n",
    "                browser_callback=self._browser_callback,\n",
    "            )\n",
    "\n",
    "            return yahoo_query\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def metadata(self, first_time=\"no\"):\n",
    "        response = complex_json_handler(yahoo_query.get_league_metadata())\n",
    "        league_metadata = pd.json_normalize(response)\n",
    "\n",
    "        league_metadata[\"game_id\"] = self.game_id\n",
    "        league_metadata.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_metadata,\n",
    "                table_name=\"LeagueMetaData\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_metadata,\n",
    "                table_name=\"LeagueMetaData\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return league_metadata\n",
    "\n",
    "\n",
    "    def set_roster_pos_stat_cat(self, first_time=\"no\"):\n",
    "        response = complex_json_handler(yahoo_query.get_league_settings())\n",
    "\n",
    "        league_settings = pd.json_normalize(response)\n",
    "        league_settings.drop(\n",
    "            [\"roster_positions\", \"stat_categories.stats\", \"stat_modifiers.stats\"],\n",
    "            axis=1,\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        league_settings[\"game_id\"] = self.game_id\n",
    "        league_settings[\"league_id\"] = self.league_id\n",
    "        league_settings.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        roster_positions = pd.DataFrame()\n",
    "        for r in response[\"roster_positions\"]:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"roster_position\"]))\n",
    "            roster_positions = pd.concat([roster_positions, row])\n",
    "\n",
    "        roster_positions[\"game_id\"] = self.game_id\n",
    "        roster_positions[\"league_id\"] = self.league_id\n",
    "        roster_positions.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        stat_categories = pd.DataFrame()\n",
    "        for r in response[\"stat_categories\"][\"stats\"]:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "            try:\n",
    "                row[\"position_type\"] = complex_json_handler(\n",
    "                    complex_json_handler(r[\"stat\"])[\"stat_position_types\"][\n",
    "                        \"stat_position_type\"\n",
    "                    ]\n",
    "                )[\"position_type\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                row[\"is_only_display_stat\"] = complex_json_handler(\n",
    "                    complex_json_handler(r[\"stat\"])[\"stat_position_types\"][\n",
    "                        \"stat_position_type\"\n",
    "                    ]\n",
    "                )[\"is_only_display_stat\"]\n",
    "            except:\n",
    "                row[\"is_only_display_stat\"] = 0\n",
    "\n",
    "            try:\n",
    "                row.drop(\"stat_position_types.stat_position_type\", axis=1, inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            stat_categories = pd.concat([stat_categories, row])\n",
    "\n",
    "        stat_categories[\"game_id\"] = self.game_id\n",
    "        stat_categories[\"league_id\"] = self.league_id\n",
    "\n",
    "        stat_modifiers = pd.DataFrame()\n",
    "        for r in response[\"stat_modifiers\"][\"stats\"]:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "            stat_modifiers = pd.concat([stat_modifiers, row])\n",
    "\n",
    "        stat_modifiers.rename(columns={\"value\": \"stat_modifier\"}, inplace=True)\n",
    "\n",
    "        stat_categories = stat_categories.merge(\n",
    "            stat_modifiers, how=\"outer\", on=\"stat_id\"\n",
    "        )\n",
    "        stat_categories.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_settings,\n",
    "                table_name=\"LeagueSettings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=roster_positions,\n",
    "                table_name=\"RosterPositions\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=stat_categories,\n",
    "                table_name=\"StatCategories\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=league_settings,\n",
    "                table_name=\"LeagueSettings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=roster_positions,\n",
    "                table_name=\"RosterPositions\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "            sql_upload_table(\n",
    "                dataframe=stat_categories,\n",
    "                table_name=\"StatCategories\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return league_settings, roster_positions, stat_categories\n",
    "\n",
    "\n",
    "    def teams_list(self, first_time=\"no\"):\n",
    "        response = yahoo_query.get_league_teams()\n",
    "        teams = pd.DataFrame()\n",
    "        for r in response:\n",
    "            team = pd.json_normalize(complex_json_handler(r[\"team\"]))\n",
    "            try:\n",
    "                manager = pd.json_normalize(\n",
    "                    complex_json_handler(team[\"managers.manager\"][0])\n",
    "                )\n",
    "            except:\n",
    "                manager = pd.json_normalize(\n",
    "                    complex_json_handler(team[\"managers\"][0][0][\"manager\"])\n",
    "                )\n",
    "            team = pd.concat([team, manager], axis=1)\n",
    "            if \"clinched_playoffs\" not in team.columns:\n",
    "                team[\"clinched_playoffs\"] = 0\n",
    "            team = team[\n",
    "                [\n",
    "                    \"clinched_playoffs\",\n",
    "                    \"has_draft_grade\",\n",
    "                    \"league_scoring_type\",\n",
    "                    \"name\",\n",
    "                    \"number_of_moves\",\n",
    "                    \"number_of_trades\",\n",
    "                    \"team_id\",\n",
    "                    \"team_key\",\n",
    "                    \"waiver_priority\",\n",
    "                    \"roster_adds.coverage_type\",\n",
    "                    \"roster_adds.coverage_value\",\n",
    "                    \"roster_adds.value\",\n",
    "                    \"guid\",\n",
    "                    \"manager_id\",\n",
    "                    \"nickname\",\n",
    "                ]\n",
    "            ]\n",
    "\n",
    "            teams = pd.concat([teams, team], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "        teams[\"name\"] = teams[\"name\"].str.decode(\"utf-8\")\n",
    "\n",
    "        teams[\"game_id\"] = self.game_id\n",
    "        teams[\"league_id\"] = self.league_id\n",
    "        teams.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=teams,\n",
    "                table_name=\"Teams\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=teams,\n",
    "                table_name=\"Teams\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return teams\n",
    "\n",
    "\n",
    "    def players_list(self, first_time=\"no\"):\n",
    "        response = yahoo_query.get_league_players()\n",
    "        players = pd.DataFrame()\n",
    "        for r in response:\n",
    "            player = pd.json_normalize(complex_json_handler(r[\"player\"]))\n",
    "            try:\n",
    "                draft_analysis = pd.json_normalize(complex_json_handler(yahoo_query.get_player_draft_analysis(player[\"player_key\"][0])))\n",
    "\n",
    "            except Exception as e:\n",
    "                if 'token_expired' in str(e):\n",
    "                    yahoo_query._authenticate()\n",
    "                else:\n",
    "                    print('Retrying after sleeping 15 min.')\n",
    "                    time.sleep(900)\n",
    "                    yahoo_query._authenticate()\n",
    "\n",
    "                draft_analysis = pd.json_normalize(complex_json_handler(yahoo_query.get_player_draft_analysis(player[\"player_key\"][0])))\n",
    "\n",
    "            draft_analysis = draft_analysis[\n",
    "                [\n",
    "                    \"draft_analysis.average_pick\",\n",
    "                    \"draft_analysis.average_round\",\n",
    "                    \"draft_analysis.average_cost\",\n",
    "                    \"draft_analysis.percent_drafted\",\n",
    "                ]\n",
    "            ]\n",
    "            player = pd.concat([player, draft_analysis], axis=1)\n",
    "            if \"status\" not in player.columns:\n",
    "                player[\"status\"] = np.nan\n",
    "\n",
    "            players = pd.concat([players, player], ignore_index=True)\n",
    "            time.sleep(2.5)\n",
    "\n",
    "\n",
    "        players[\"game_id\"] = self.game_id\n",
    "        players[\"league_id\"] = self.league_id\n",
    "        players.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=players,\n",
    "                table_name=\"Players\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=players,\n",
    "                table_name=\"Players\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return players\n",
    "\n",
    "\n",
    "    def draft_results(self, first_time=\"no\"):\n",
    "        response = yahoo_query.get_league_draft_results()\n",
    "        draft_results = pd.DataFrame()\n",
    "        for r in response:\n",
    "            row = pd.json_normalize(complex_json_handler(r[\"draft_result\"]))\n",
    "            draft_results = pd.concat([draft_results, row])\n",
    "\n",
    "        draft_results[\"game_id\"] = self.game_id\n",
    "        draft_results[\"league_id\"] = self.league_id\n",
    "        draft_results.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=draft_results,\n",
    "                table_name=\"DraftResults\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=draft_results,\n",
    "                table_name=\"DraftResults\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return draft_results\n",
    "\n",
    "\n",
    "    def matchups_by_week(self, first_time=\"no\"):\n",
    "        m = []\n",
    "        team_a = pd.DataFrame()\n",
    "        team_b = pd.DataFrame()\n",
    "        response = yahoo_query.get_league_matchups_by_week(1)\n",
    "        for data in response:\n",
    "            m.append(complex_json_handler(data[\"matchup\"]))\n",
    "        matchups = pd.DataFrame()\n",
    "        for r in m:\n",
    "            matchup = pd.json_normalize(r)\n",
    "            matchup = matchup[\n",
    "                [\n",
    "                    \"is_consolation\",\n",
    "                    \"is_matchup_recap_available\",\n",
    "                    \"is_playoffs\",\n",
    "                    \"is_tied\",\n",
    "                    \"matchup_recap_title\",\n",
    "                    \"matchup_recap_url\",\n",
    "                    \"status\",\n",
    "                    \"week\",\n",
    "                    \"week_end\",\n",
    "                    \"week_start\",\n",
    "                    \"winner_team_key\",\n",
    "                ]\n",
    "            ]\n",
    "            try:\n",
    "                team_a = pd.json_normalize(\n",
    "                    complex_json_handler(r[\"matchup_grades\"][0][\"matchup_grade\"])\n",
    "                )\n",
    "                team_a[\"points\"] = complex_json_handler(r[\"teams\"][0][\"team\"])[\n",
    "                    \"team_points\"\n",
    "                ][\"total\"]\n",
    "                team_a[\"projected_points\"] = complex_json_handler(\n",
    "                    r[\"teams\"][0][\"team\"]\n",
    "                )[\"team_projected_points\"][\"total\"]\n",
    "\n",
    "            except:\n",
    "                team_a = pd.json_normalize(complex_json_handler(r[\"teams\"][0][\"team\"]))\n",
    "                team_a = team_a[\n",
    "                    [\"team_key\", \"team_points.total\", \"team_projected_points.total\"]\n",
    "                ]\n",
    "                team_a[\"grade\"] = np.nan\n",
    "\n",
    "            team_a = team_a.add_prefix(\"team_a_\")\n",
    "\n",
    "            try:\n",
    "                team_b = pd.json_normalize(\n",
    "                    complex_json_handler(r[\"matchup_grades\"][1][\"matchup_grade\"])\n",
    "                )\n",
    "                team_b[\"points\"] = complex_json_handler(r[\"teams\"][1][\"team\"])[\n",
    "                    \"team_points\"\n",
    "                ][\"total\"]\n",
    "                team_b[\"projected_points\"] = complex_json_handler(\n",
    "                    r[\"teams\"][1][\"team\"]\n",
    "                )[\"team_projected_points\"][\"total\"]\n",
    "\n",
    "            except:\n",
    "                team_b = pd.json_normalize(complex_json_handler(r[\"teams\"][1][\"team\"]))\n",
    "                team_b = team_b[\n",
    "                    [\"team_key\", \"team_points.total\", \"team_projected_points.total\"]\n",
    "                ]\n",
    "                team_b[\"grade\"] = np.nan\n",
    "            team_b = team_b.add_prefix(\"team_b_\")\n",
    "\n",
    "            matchup = pd.concat([matchup, team_a, team_b], axis=1)\n",
    "\n",
    "            matchups = pd.concat([matchups, matchup])\n",
    "\n",
    "        try:\n",
    "            matchups.drop([\"teams\", \"matchup_grades\"], axis=1, inplace=True)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        matchups[\"game_id\"] = self.game_id\n",
    "        matchups[\"league_id\"] = self.league_id\n",
    "        matchups.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=matchups,\n",
    "                table_name=\"Matchups\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=matchups,\n",
    "                table_name=\"Matchups\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return matchups\n",
    "\n",
    "\n",
    "    def team_standings(self, first_time=\"no\"):\n",
    "        standings = pd.DataFrame()\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                response = yahoo_query.get_team_standings(i)\n",
    "                if bool(response) == True:\n",
    "                    row = pd.json_normalize(complex_json_handler(response))\n",
    "                    row[\"team_id\"] = i\n",
    "                    standings = pd.concat([standings, row])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        standings[\"game_id\"] = self.game_id\n",
    "        standings[\"league_id\"] = self.league_id\n",
    "        standings.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=standings,\n",
    "                table_name=\"Standings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=standings,\n",
    "                table_name=\"Standings\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return standings\n",
    "\n",
    "\n",
    "    def team_roster_by_week(self, first_time=\"no\"):\n",
    "        team_rosters = pd.DataFrame()\n",
    "        for t in range(1, 13):\n",
    "            try:\n",
    "                for w in range(1, 19):\n",
    "                    try:\n",
    "                        response = complex_json_handler(yahoo_query.get_team_roster_by_week(t, w))\n",
    "                        row = pd.json_normalize(complex_json_handler(response[\"players\"][0][\"player\"]))\n",
    "                        row[\"team_id\"] = t\n",
    "                        row[\"week\"] = w\n",
    "                        team_rosters = pd.concat([team_rosters, row])\n",
    "                        time.sleep(1)\n",
    "                    except:\n",
    "                        print(f'team: {t}\\nweek: {w}')\n",
    "                        continue\n",
    "            except:\n",
    "                print(f'team: {t}\\nweek: {w}')\n",
    "                continue\n",
    "\n",
    "        team_rosters[\"game_id\"] = self.game_id\n",
    "        team_rosters[\"league_id\"] = self.league_id\n",
    "        team_rosters.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=team_rosters,\n",
    "                table_name=\"TeamRosters\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=team_rosters,\n",
    "                table_name=\"TeamRosters\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return team_rosters\n",
    "\n",
    "\n",
    "    def player_stats_by_week(self, first_time=\"no\"):\n",
    "        players = sql_grab_table(\"Players\")\n",
    "        player_keys = list(players[\"player_keys\"])\n",
    "        player_stats = pd.DataFrame()\n",
    "        for k in player_keys:\n",
    "            i = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    r1 = yahoo_query.get_player_stats_by_week(k, i)\n",
    "                    r2 = yahoo_query.get_player_percent_owned_by_week(k, i)\n",
    "                    if bool(r1) == True and bool(2) == True:\n",
    "                        data = complex_json_handler(r1)\n",
    "                        player = pd.json_normalize(data)\n",
    "                        stats = data[\"player_stats\"][\"stats\"]\n",
    "                        player_stats = pd.DataFrame()\n",
    "                        for r in stats:\n",
    "                            stat = pd.json_normalize(complex_json_handler(r[\"stat\"]))\n",
    "                            stat[\"player_key\"] = player[\"player_key\"]\n",
    "                            stat[\"week\"] = player[\"player_stats.week\"]\n",
    "                            stat[\"total_points_week\"] = player[\"player_points.total\"]\n",
    "                            player_stats = pd.concat([player_stats, stat])\n",
    "\n",
    "                        ownership = pd.json_normalize(complex_json_handler(r2))\n",
    "                        ownership = ownership[\n",
    "                            [\"player_key\", \"percent_owned.value\", \"percent_owned.delta\"]\n",
    "                        ]\n",
    "\n",
    "                        player_stats = player_stats.merge(\n",
    "                            ownership,\n",
    "                            how=\"outer\",\n",
    "                            left_on=\"player_key\",\n",
    "                            right_on=\"player_key\",\n",
    "                        )\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "        player_stats[\"game_id\"] = self.game_id\n",
    "        player_stats[\"league_id\"] = self.leauge_id\n",
    "        player_stats.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        if str(first_time).upper() == \"YES\":\n",
    "            sql_upload_table(\n",
    "                dataframe=player_stats,\n",
    "                table_name=\"PlayerStats\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"replace\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif str(first_time).upper() == \"NO\":\n",
    "            sql_upload_table(\n",
    "                dataframe=player_stats,\n",
    "                table_name=\"PlayerStats\",\n",
    "                data_schema=\"dbo\",\n",
    "                chunksize=500,\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        return player_stats\n",
    "\n",
    "\n",
    "    def all_game_keys(self):\n",
    "        response = unpack_data(yahoo_query.get_all_yahoo_fantasy_game_keys())\n",
    "        league_keys = pd.read_csv(\"../assests/ID.csv\")\n",
    "        game_keys = pd.DataFrame()\n",
    "        for r in response:\n",
    "            row = pd.DataFrame(complex_json_handler(r[\"game\"]), index=[0])\n",
    "            game_keys = pd.concat([game_keys, row])\n",
    "\n",
    "        game_keys.reset_index(drop=True, inplace=True)\n",
    "        game_keys = game_keys[game_keys[\"season\"] >= 2012]\n",
    "        game_keys = game_keys.merge(\n",
    "            league_keys,\n",
    "            how=\"outer\",\n",
    "            left_on=[\"game_id\", \"season\"],\n",
    "            right_on=[\"game_id\", \"season\"],\n",
    "        )\n",
    "        game_keys.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        sql_upload_table(\n",
    "            dataframe=game_keys,\n",
    "            table_name=\"GameKeys\",\n",
    "            data_schema=\"dbo\",\n",
    "            chunksize=500,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        return game_keys\n",
    "\n",
    "\n",
    "    def all_nfl_weeks(self):\n",
    "        game_keys = sql_grab_table(\"GameKeys\")\n",
    "        game_id = list(game_keys[\"game_id\"])\n",
    "        weeks = pd.DataFrame()\n",
    "        for g in game_id:\n",
    "            response = yahoo_query.get_game_weeks_by_game_id(g)\n",
    "            for r in response:\n",
    "                row = pd.json_normalize(complex_json_handler(r[\"game_week\"]))\n",
    "                row[\"game_id\"] = g\n",
    "                weeks = pd.concat([weeks, row])\n",
    "\n",
    "        weeks.rename(columns={\"display_name\": \"week\"}, inplace=True)\n",
    "        weeks.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "        sql_upload_table(\n",
    "            dataframe=weeks,\n",
    "            table_name=\"NFLWeeks\",\n",
    "            data_schema=\"dbo\",\n",
    "            chunksize=500,\n",
    "            if_exists=\"replace\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        return weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = get_season()\n",
    "NFL_DATES_DF, LEAGUE_ID_DF = league_season_info()\n",
    "# TODAY = np.datetime64(\"today\", \"D\")\n",
    "TODAY = np.datetime64(\"2021-09-28\")\n",
    "NFL_WEEK = NFL_DATES_DF[\"Week\"][(NFL_DATES_DF[\"End_Date\"] >= TODAY) & (NFL_DATES_DF[\"Start_Date\"] <= TODAY)].values[0]\n",
    "WEEKS = list(range(NFL_WEEK, 0, -1))\n",
    "\n",
    "\n",
    "\n",
    "PATH = Path.cwd().parents[0]\n",
    "LEAGUE_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"league_ID\"].values[0]\n",
    "GAME_ID = LEAGUE_ID_DF[LEAGUE_ID_DF[\"season\"] == SEASON][\"game_ID\"].values[0]\n",
    "CONSUMER_KEY = os.getenv(\"yahoo_client_id\")\n",
    "CONSUMER_SECRET = os.getenv(\"yahoo_client_secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time = \"yes\"\n",
    "league = league_season_data(\n",
    "    auth_dir=PATH,\n",
    "    league_id=LEAGUE_ID,\n",
    "    game_id=GAME_ID,\n",
    "    game_code=\"nfl\",\n",
    "    offline=False,\n",
    "    all_output_as_json=False,\n",
    "    consumer_key=CONSUMER_KEY,\n",
    "    consumer_secret=CONSUMER_SECRET,\n",
    "    browser_callback=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29258400a8f826869c35241d002ab1a2d58355eacb0fc692319d3b839b315963"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('yahoo.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
